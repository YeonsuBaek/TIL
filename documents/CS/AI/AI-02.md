# 인공지능 - 지능적 에이전트

> ### Index
>
> 1. 에이전트와 환경
> 2. 좋은 행동: 합리성 개념
> 3. 환경의 본성
> 4. 에이전트의 구조
> 5. 요약

> ### 학습 목표
>
> 에이전트의 본성, 환경의 다양성, 그리고 에이전트의 다양한 종류를 논의한다.

## 1. 에이전트와 환경

에이전트와 환경의 상호작용 요소에는 감지기(sensor), 환경(environment), 작동기(actuator)가 있다.

![](https://velog.velcdn.com/images/yeonsubaek/post/8ebe4bdd-ab09-4368-a66b-9a481c4ebfb7/image.jpeg)

환경에서 지각(먼지나 장애물 여부)이 감지기에 들어오면 에이전트가 함수가 실행되어 상태를 추론하고 동작한다. 이때 정보와 환경에 맞는 올바른 행동을 해야 한다. 작동기를 통해 다시 환경으로 돌아가 동작이 수행된다.

![](https://velog.velcdn.com/images/yeonsubaek/post/753f755e-2300-47cb-9f8c-226be2119279/image.jpeg)

사각형 A와 B라는 장소로 이루어진 진공청소기 세계가 있다고 가정하자.
진공청소기 에이전트는 자신이 어디에 있는지, 그 공간이 깨끗한지 더러운지 환경에 대한 정보를 지각한다.  
에이전트가 선택할 수 있는 동작은 왼쪽이나 오른쪽으로 이동하거나 먼지를 흡입하거나 아무 일도 하지 않는 것이다.

위와 같은 인식 순서에 대한 동작을 표로 나타내면 다음과 같다.

| 인식 순서              | 동작  |
| ---------------------- | ----- |
| [A, Clean]             | Right |
| [A, Dirty]             | Suck  |
| [B, Clean]             | Left  |
| [B, Dirty]             | Suck  |
| [A, Clean], [A, Clean] | Right |
| [A, Clean], [A, Dirty] | Suck  |
| ...                    | ...   |

인식 순서의 경우의 수가 너무 많다. 어떻게 하면 효율적으로 처리할 수 있을까?

## 2. 좋은 행동: 합리성 개념

### 2-1. 성과 측도

합리적 에이전트는 옳은 일(바람직함)을 하는 에이전트이다.

결과 주의란 에이전트의 옳은 일은 성과 측도로 구체화한다는 것이다. 성과 측정은 에이전트의 상태가 아니라 환경의 상태가 대상이 된다. 예를 들어, 에이전트가 먼지를 빨아들인 양과 시간마다 깨끗한 방 중에 깨끗한 방에 초점을 맞추는 것이다.

에이전트가 어떻게 행동해야 하는지 기준으로 삼기보다 **환경이 실제로 어떻게 변하는 것이 바람직한지** 기준으로 삼는 것을 성과 측도 설계라고 한다.

### 2-2. 합리성

합리성을 결정하는 요인에는 성과 측도, 사전 지식, 동작들, 지각열이 있다.

이러한 요인을 바탕으로 합리적 에이전트를 정의하면 다음과 같다. :  
_각각의 가능한 지각열에 대해, 합리적인 에이전트는 자신의 지각열과 에이전트의 내장 지식이 제공하는 증거에 기초해서 성과 측정치를 극대화할 만한 동작을 선택해야 한다._

#### 진공청소기 예시

합리적인 예이전트란

- 성과 측정 방식이 어떤 것인지
- 환경에 관해 알려진 것이 무엇인지
- 에이전트에 어떤 감지기와 작동기가 있는지

다음과 같이 가정하기로 하자

- 각 시간 단계에서 깨끗한 사각형 마다 1점 획득
- 진공청소기의 수명의 1,000개의 시간 단계
- 꺠끗한 사각형은 깨끗한 상태를 유지하고 진공청소기가 먼지를 빨아들인 사각형은 깨끗해진다
- Left, Right 동작은 각각 에이전트를 왼쪽, 오른쪽으로 이동시킨다. 단 사각형 밖으로 이동을 불가능하다
- 가능한 동작은 Left, Right, Suck 뿐이다
- 에이전트는 자신의 위치 및 먼지 유무를 정확히 인식한다

### 2-3. 전지, 학습, 자율성

합리성과 전지를 신중하게 구분할 필요가 있다. 합리성은 **기대 성과**를 극대화하는 반면, 완벽함(전지)은 실제 성과를 극대화한다.  
전지한 에이전트는 자신의 동작의 실제 결과를 미리 알고 그에 따라 행동할 수 있다. 그러나 현실에서 그러한 전지전능함은 불가능하다.  
최상의 동작을 하는 에이전트 설계는 불가능하다. 합리적 에이전트의 정의에 의하면 합리적 선택은 오직 지금까지의 지각열에만 의존하기 때문이다.

합리적 에이전트는 정보를 수집(탐험)해야 할 뿐만 아니라 자신이 지각한 것에서 최대한 많은 것을 배워야(학습) 한다. 환경 사전 지식(초기구성)을 가지고 정보를 수집하고 학습을 하는 순서에 따라 자율성을 확보해 나가야 한다.

## 3. 환경의 본성

합리적인 에이전트를 실제로 구축하기 전 과제 환경을 생각한다. 과제 환경은 문제이고, 합리적 에이전트는 해답이다.

### 3-1. 과제 환경의 명시

과제 환경이란 성과 측정 방식과 환경, 그리고 에이전트의 작동기 및 감+지기를 말하고, PEAS(Performance, Environment, Actuators, Sensors)라고도 불린다.

에이전트를 설계할 때 그 과제 환경을 최대한 완전하게 서술하는 것을 항상 첫 단계에 해야한다.

### 3-2. 과제 환경의 속성

- 완전 관찰 가능한 환경 vs 부분 관찰 가능한 환경
  - 동작과 관련된 모든 정보를 관측이 성과 측도를 좌우한다.
- 단일 에이전트 환경(경쟁적) vs 다중 에이전트 환경 (협동적)
- 결정론적 환경 vs 확률론적 환경
  - 다음 상태가 현재 상태와 에이전트 수행 동작으로 결정되는가?
- 일화적 환경 vs 순차적 환경

- 정적 환경 vs 동적 환경
  - 다음 행동을 하는 동안 환경이 변하는가?
- 이산적 환경 vs 연속적 환경
  - 환경의 상태, 시간의 처리방식, 에이전트의 지각 및 동작과 관련
- 기지(known) 환경 vs 미지(unknown) 환경

## 4. 에이전트의 구조

아키텍처와 프로그램을 합쳐 에이전트라고 한다. 에이전트 프로그램이란 에이전트 함수(지각을 동작으로 사상하는 함수)의 구현이다.

에이전트 아키텍처는 물리적 감지기와 작동기를 갖춘 계산 장치로, 지각들을 프로그램에 제공하고, 프로그램을 실행하고, 프로그램이 선택한 동작들을 작동기에 공급해서 동작한다.

### 4-1. 에이전트 프로그램

`TABLE-DRIVEN-AGENT` 프로그램은 각각의 새 지각마다 호출되고 매번 하나의 동작을 돌려준다. 이 프로그램은 완전한 지각열을 메모리 안에 유지한다.

지속 변수는 `percepts` 와 `table` 로 구성되어 있다.  
percepts는 지각들의 순차열로 초기에는 비어있다.  
table은 동작들의 표로 지각열을 색인으로 하고 처음부터 완전히 채워져 있다.

```
function TABLE-DRIVEN-AGENT([location, status]) return 하나의 동작

percept를 percepts의 끝에 추가한다.
action <- LOOKUP(percents, table)
return action;
```

표의 항목을 구성하는데 공간적, 시간적 제약이 있어 표 위주로 에이전트를 구축하는 접근방식은 실패할 수 밖에 없다.

따라서 작은 프로그램으로 가능한 합리적으로 행동을 산출할 수 있는 프로그램을 작성하는 방법을 찾는 것이 핵심적인 도전 과제이다.

### 4-2. 에이전트 종류

에이전트 종류에는 단순 반사 에이전트, 모형 기반 에이전트, 목표 기반 에이저트, 효용 기반 에이전트가 있다.

#### 단순 반사 에이전트

단순 반사 에이전트는 가장 단순한 형태의 에이전트이다. 항상 현재 지각에 근거해서 동작을 선택할 뿐, 지각 역사(percepts)의 나머지 부분은 무시한다.

```
function REFLEX-VACUUM-AGENT([location, status]) return 하나의 동작

if status = Dirty then return Suck
else if location = A then return Right
else if location B then return Left
```

---

학교 인공지능 강의를 듣고 정리한 내용
